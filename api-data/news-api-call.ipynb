{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from api_keys import api_key\n",
    "import pprint as pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WMT', 'AMZN', 'XOM', 'AAPL', 'UNH', 'CVS', 'BRKA', 'GOOGL', 'MCK',\n",
       "       'CVX', 'ABC', 'COST', 'MSFT', 'CAH', 'CI', 'MPC', 'PSX', 'VLO',\n",
       "       'F', 'HD', 'GM', 'ELV', 'JPM', 'KR', 'CNC', 'VZ', 'WBA', 'FNMA',\n",
       "       'CMCSA', 'T', 'META', 'BAC', 'TGT', 'DELL', 'ADM', 'C', 'UPS',\n",
       "       'PFE', 'LOW', 'JNJ', 'FDX', 'HUM', 'ET', 'FMCC', 'PEP', 'WFC',\n",
       "       'DIS', 'COP', 'TSLA', 'PG', 'GE', 'ACI', 'MET', 'GS', 'SYY', 'RTX',\n",
       "       'BA', 'SNEX', 'LMT', 'MS', 'INTC', 'HPQ', 'SNX', 'IBM', 'HCA',\n",
       "       'PRU', 'CAT', 'MRK', 'INT', 'EPD', 'ABBV', 'PAGP', 'DOW', 'AIG',\n",
       "       'AXP', 'CHTR', 'TSN', 'DE', 'CSCO', 'ALL', 'DAL', 'TJX', 'PGR',\n",
       "       'AAL', 'PFGC', 'PBF', 'NKE', 'BBY', 'BMY', 'UAL', 'TMO', 'QCOM',\n",
       "       'ABT', 'KO', 'ORCL', 'NUE', 'GD', 'COF', 'DINO', 'DG', 'ARW',\n",
       "       'OXY', 'TRV', 'NOC', 'HON', 'MMM', 'USFD', 'WBD', 'LEN', 'DHI',\n",
       "       'JBL', 'LNG', 'AVGO', 'KMX', 'SBUX', 'MOH', 'UBER', 'PM', 'NFLX',\n",
       "       'NRG', 'MDLZ', 'DHR', 'CRM', 'PARA', 'CBRE', 'MU', 'V', 'SO',\n",
       "       'UNFI', 'PCAR', 'DUK', 'LLY', 'HPE', 'DLTR', 'LAD', 'CMI', 'PAG',\n",
       "       'PYPL', 'USB', 'GILD', 'AN', 'NVDA', 'KHC', 'AMGN', 'AMAT', 'EOG',\n",
       "       'TFC', 'M', 'UNP', 'CHRW', 'RAD', 'CEG', 'AVT', 'PXD', 'LUV',\n",
       "       'CDW', 'AMD', 'PNC', 'MCD', 'CLF', 'FCX', 'BLDR', 'OKE', 'HIG',\n",
       "       'SCHW', 'STLD', 'MA', 'SHW', 'GPC', 'PCG', 'WCC', 'MUSA', 'WRK',\n",
       "       'IP', 'BKR', 'X', 'NEE', 'TRGP', 'LEA', 'JLL', 'GT', 'MAR', 'MMC',\n",
       "       'MO', 'CPNG', 'CARR', 'HAL', 'DK', 'KMB', 'TXN', 'BK', 'MAN',\n",
       "       'WHR', 'WM', 'AEP', 'EMR', 'AFL', 'CTSH', 'BDX', 'BJ', 'MRNA',\n",
       "       'DTE', 'KMI', 'THC', 'DVN', 'MOS', 'EXC', 'GIS', 'GLP', 'WDC',\n",
       "       'LNC', 'ROST', 'SYK', 'KD', 'KSS', 'SWK', 'CL', 'BLK', 'EL',\n",
       "       'FISV', 'PPG', 'ADBE', 'SQ', 'SYF', 'PFG', 'LUMN', 'CTVA', 'ANDE',\n",
       "       'LRCX', 'EIX', 'D', 'BKNG', 'PWR', 'EXPD', 'LHX', 'RS', 'LYV',\n",
       "       'DISH', 'DD', 'ADP', 'GPI', 'ARMK', 'THO', 'DXC', 'VTRS', 'RGA',\n",
       "       'AZO', 'PHM', 'ITW', 'PH', 'BWA', 'WLK', 'ED', 'GPS', 'OPEN',\n",
       "       'JWN', 'ABG', 'BALL', 'K', 'XEL', 'GWW', 'DFS', 'BAX', 'SWN',\n",
       "       'DCP', 'J', 'LH', 'CSX', 'JBHT', 'JXN', 'FIS', 'BERY', 'SRE',\n",
       "       'IQV', 'ORLY', 'LDOS', 'AMP', 'OMC', 'TSCO', 'GLW', 'ECL', 'IEP',\n",
       "       'KDP', 'L', 'EQH', 'SAH', 'FOXA', 'ETR', 'FLR', 'VST', 'STT',\n",
       "       'OTIS', 'CVNA', 'RSG', 'ACM', 'UHS', 'VMW', 'MGM', 'CASY', 'CCK',\n",
       "       'TXT', 'LKQ', 'NSC', 'INTU', 'APD', 'BSX', 'AGCO', 'HSIC', 'APH',\n",
       "       'AES', 'OVV', 'HRL', 'AA', 'IFF', 'DKS', 'ES', 'W', 'CYH', 'ALLY',\n",
       "       'REGN', 'LSXMA', 'APA', 'QRTEA', 'FE', 'ADI', 'R', 'CAR', 'UNM',\n",
       "       'NEM', 'VFC', 'CHK', 'MHK', 'MKL', 'EXPE', 'CZR', 'URI', 'APO',\n",
       "       'DVA', 'HES', 'FNF', 'CAG', 'UNVR', 'RJF', 'SEB', 'CF', 'SPGI',\n",
       "       'WRB', 'AAP', 'EME', 'WMB', 'IPG', 'TA', 'AMT', 'TAP', 'HII',\n",
       "       'NVR', 'EMN', 'NSIT', 'HSY', 'NWSA', 'TOL', 'ULTA', 'AIZ', 'WY',\n",
       "       'BIIB', 'DAN', 'UGI', 'CHWY', 'OMI', 'DGX', 'PEG', 'EBAY', 'MTZ',\n",
       "       'OC', 'CE', 'ATUS', 'ALK', 'SPTN', 'FANG', 'ICE', 'DRI', 'UFPI',\n",
       "       'WEC', 'YUMC', 'ENLC', 'NWL', 'GPK', 'OLN', 'FITB', 'CNP', 'COMM',\n",
       "       'KLAC', 'JBLU', 'MSI', 'CFG', 'CTRA', 'AVY', 'PVH', 'GXO', 'PII',\n",
       "       'GPN', 'ARNC', 'VRTX', 'CMC', 'ALV', 'STZ', 'HLT', 'FL', 'HUN',\n",
       "       'BURL', 'HTZ', 'MAS', 'WSM', 'CMG', 'MTB', 'LPLA', 'CMS', 'CPB',\n",
       "       'AJG', 'BX', 'DOV', 'ODP', 'PKG', 'BHF', 'BECN', 'ABNB', 'BCC',\n",
       "       'BAH', 'WAB', 'ON', 'OSK', 'BEN', 'TMHC', 'AMRK', 'KEY', 'ARKO',\n",
       "       'LULU', 'ORI', 'ZTS', 'MRO', 'SJM', 'HBAN', 'NGL', 'INGR', 'FBIN',\n",
       "       'PPL', 'SANM', 'BBBY', 'CTAS', 'NCR', 'ABM', 'ROK', 'NTRS', 'XPO',\n",
       "       'SAIC', 'AEE', 'FAF', 'BBWI', 'RF', 'ATVI', 'AVTR', 'GNW', 'EQT',\n",
       "       'SKX', 'LSTR', 'KNX', 'SIVBQ', 'PARR', 'ALB', 'VMC', 'WSO', 'KKR',\n",
       "       'EQIX', 'SON', 'NOW', 'RHI'], dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'Resourses/newsKeyWords.csv'  # Update this with the correct path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the tickers are in the second column (index 1)\n",
    "tickers = df.iloc[:, 1].unique()  # Extract unique tickers to avoid duplicate API calls\n",
    "\n",
    "tickers\n",
    "# Limit to the first 100 tickers\n",
    "# tickers_100 = tickers[200:]\n",
    "# tickers_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-01-02', '2023-02-01', '2023-03-01', '2023-04-03', '2023-05-01', '2023-06-01', '2023-07-03', '2023-08-01', '2023-09-01', '2023-10-02', '2023-11-01', '2023-12-01']\n",
      "['2023-01-31', '2023-02-28', '2023-03-31', '2023-04-28', '2023-05-31', '2023-06-30', '2023-07-31', '2023-08-31', '2023-09-29', '2023-10-31', '2023-11-30', '2023-12-29']\n"
     ]
    }
   ],
   "source": [
    "# Generate the first business day for each month from January to December 2023\n",
    "business_start_2023 = pd.date_range(start='2023-01-01', end='2023-12-31', freq='BMS')\n",
    "business_start_2023 = business_start_2023.strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "# Generate the last business day for each month from January to December 2023\n",
    "business_last_2023 = pd.date_range(start='2023-01-01', end='2023-12-31', freq='BM')\n",
    "business_last_2023 = business_last_2023.strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "# Display the generated dates\n",
    "print(business_start_2023)\n",
    "print(business_last_2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OXY'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming tickers and business_days_2023 are already defined in your script\n",
    "\n",
    "# Limit to the first 5 tickers\n",
    "#tickers = tickers[:2]\n",
    "\n",
    "# Limit to the first date\n",
    "#business_start_2023 = business_start_2023[:4]\n",
    "#business_last_2023 = business_last_2023[:4]\n",
    "tickers[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to fetch and process news data for each ticker\n",
    "def fetch_news_data(tickers, start_dates, end_dates, api_key, df):\n",
    "    # Define short names for each month\n",
    "    month_names = [date[:7] for date in start_dates]  # Extract year-month from dates\n",
    "    short_month_names = [date.strftime(\"%b\") for date in pd.to_datetime(start_dates)]\n",
    "\n",
    "    # Add columns for each short month name and initialize 'homepages' column\n",
    "    for short_month in short_month_names:\n",
    "        if short_month not in df.columns:\n",
    "            df[short_month] = ''  # Initialize month columns\n",
    "    if 'homepages' not in df.columns:\n",
    "        df['homepages'] = ''  # Initialize homepages column\n",
    "\n",
    "    for ticker in tickers:  # Processing the next 100 tickers\n",
    "        homepages_combined = set()\n",
    "        for start_date, end_date, short_month in zip(start_dates, end_dates, short_month_names):\n",
    "            url = f\"https://api.polygon.io/v2/reference/news?ticker={ticker}&published_utc.gt={start_date}&published_utc.lt={end_date}&limit=5&apiKey={api_key}\"\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json().get('results', [])\n",
    "\n",
    "                keywords_combined = []\n",
    "                for item in data:\n",
    "                    keywords = item.get('keywords', [])\n",
    "                    keywords_combined.extend(keywords)\n",
    "\n",
    "                    homepage_url = item.get('publisher', {}).get('homepage_url', '')\n",
    "                    if homepage_url:\n",
    "                        homepages_combined.add(homepage_url)\n",
    "                \n",
    "                # Safely retrieve existing keywords for the month\n",
    "                if ticker in df['Ticker'].values and short_month in df.columns:\n",
    "                    existing_keywords = df.loc[df['Ticker'] == ticker, short_month].values[0]\n",
    "                    existing_keywords = existing_keywords if isinstance(existing_keywords, str) else ''\n",
    "                else:\n",
    "                    existing_keywords = ''\n",
    "\n",
    "                # Join keywords with semicolons\n",
    "                updated_keywords = '; '.join([existing_keywords, '; '.join(keywords_combined)]).strip('; ')\n",
    "                df.loc[df['Ticker'] == ticker, short_month] = updated_keywords\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(f\"Failed to fetch news for {ticker}\")\n",
    "                print(response.text)\n",
    "\n",
    "            time.sleep(12)  # Rate limiting\n",
    "\n",
    "        # Safely update homepages for the ticker\n",
    "        if ticker in df['Ticker'].values:\n",
    "            existing_homepages = df.loc[df['Ticker'] == ticker, 'homepages'].values[0]\n",
    "            existing_homepages = existing_homepages if isinstance(existing_homepages, str) else ''\n",
    "        else:\n",
    "            existing_homepages = ''\n",
    "\n",
    "        updated_homepages = ' '.join(set(existing_homepages.split() + list(homepages_combined))).strip()\n",
    "        df.loc[df['Ticker'] == ticker, 'homepages'] = updated_homepages\n",
    "\n",
    "    return df\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df['homepages'] = ''\n",
    "\n",
    "# Fetch and process news data\n",
    "df = fetch_news_data(tickers, business_start_2023, business_last_2023, api_key, df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Resourses/newsKeyWords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['homepages', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
